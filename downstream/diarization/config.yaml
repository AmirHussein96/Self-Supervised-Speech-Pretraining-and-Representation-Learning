runner:
  total_steps: 30000
  gradient_clipping: 1
  gradient_accumulate_steps: 4

  log_step: 5000
  eval_step: 10000
  save_step: 10000
  max_keep: 1
  eval_dataloaders:
    - dev
    - test

optimizer:
  name: AdamW
  lr: 2.e-4

downstream_expert:
  datarc:
    chunk_size: 2000
    frame_shift: 160 # this should be aligned with upstrema model
    subsampling: 1
    label_delay: 0
    num_speakers: 2
    rate: 16000

  loaderrc:
    num_workers: 8
    train_batchsize: 8
    eval_batchsize: 1
    train_dir: ./downstream/diarization/data/train
    dev_dir: ./downstream/diarization/data/dev
    test_dir: ./downstream/diarization/data/test
  
  scorerc:
    score_dir: ./downstream/diarization/wav2vec2_scoring
    save_predictions: True

  modelrc: 
    rnn_layers: 1
    hidden_size: 512
